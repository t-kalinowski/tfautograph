---
title: "Autograph Basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{autograph-basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
reticulate::use_virtualenv("tf2", TRUE)
```

```{r setup}
library(magrittr)
library(reticulate)
library(tensorflow)
library(tfdatasets)

library(tfautograph)
tf$version$VERSION
```

The R package `tfautograph` helps you write natural R code for tensorflow. 

It allows you to use tensors in R control flow expressions like `if`, `while`,
`for`, `break`, and `next`, which can automatically be translated to build a
tensorflow graph  (hence the name, __auto__ __graph__). 

However tfautograph doesn't just work in graph mode--it also works in eager mode. In addition, it provides a handful of thin wrappers around tensorflow control primitives
and some S3 methods for `TensorArrays` that make their use from R a little more
ergonomic.

This vignette goes through some of the main features and then goes into how it
works a little.

### Usage

The primary workhorse function of the package is the function `autograph()`. For
most use-cases, this is the only function from the package you will need or want
to call. It can either take a function or an expression. The following two uses
are equivalent.

```{r}
# pass a function to autograph()
fn <- function(x) if(x > 0) x * x else x
square_if_positive <- autograph(fn) 

# pass an expression to autograph()
square_if_positive <- autograph(function(x) if(x > 0) x * x else x)
```

Now `square_if_positive` is a function that can accept a tensor as an argument. 

```{r}
x <- tf$convert_to_tensor(5)
y <- tf$convert_to_tensor(-5)
square_if_positive(x)
square_if_positive(y)
```

Note that if you're in a context where tensorflow is executing eagerly, `autograph()` doesn't change that--`square_if_positive()` is still executing eagerly. You can test that by inserting some R `print` statements to see when a branch is evaluated.

```{r}
square_if_positive_verbose <- autograph(function(x) {
  if (x > 0) {
    message("Tracing true branch")
    x * x
  } else {
    message("Tracing false branch")
    x
  }
})

square_if_positive_verbose(x)
square_if_positive_verbose(x)
square_if_positive_verbose(x)

square_if_positive_verbose(y)
square_if_positive_verbose(y)
square_if_positive_verbose(y)
```

The easiest way to enter a context where tensorflow is not executing eagerly anymore and instead is in **graph mode** is to call python's `tf.function()`. (Because `function` is a reserved word for the R parser, there is a convenient wrapper provided by the tensorflow `R` package: `tf_function()`)

```{r}
graph_fn <- tf_function(square_if_positive_verbose)

graph_fn(x)
graph_fn(x)
graph_fn(x)

graph_fn(y)
graph_fn(y)
graph_fn(y)
```

In graph mode, both branches of the `if` expression are traced into a tensorflow graph the first time the function is called and the resultant graph is cached by `tf.function()`. Then on subsequent calls only the cached graph is evaluated.

The key takeaways are that `autograph()` helps you write natural R code and use tensors in expressions where R wouldn't otherwise accept them. And that `autograph` is smart enough to do the right thing in both eager mode and graph mode. 


### Control Flow
tfautograph will translate R control flow statements to tensorflow. This includes `if`, `while`, `for`, `break`, `next`, and `switch`. Here is handy summary table of the translation endpoints.

```{r, echo = FALSE, results = 'asis'}
knitr::kable(matrix(
  ncol = 3, byrow = TRUE,
  dimnames =
    list(c(),  
   c("R expression", "Graph Mode Translation", "Eager Mode Translation")),
  c("`if(x)`", "`tf$cond(x, ...)`", "```if(x$`__bool__`())```",
    "`while(x)`",  "`tf$while_loop(...)`", "`while(as.logical(x))`",
    "`for(x in tensor)`", "`tf$while_loop(...)`", "`while(!is.null(x <- iter_next(tensor))`",
    "`for(x in tfdataset)`", "`Dataset$reduce()`", "`while(!is.null(x <- iter_next(dataset))`"
  ),
))
```

Lets go through them one at a time. 


#### `if`


In eager mode, `if(eager_tensor)` is translated to ```if(eager_tensor$`__bool__`())```. (Essentially, a slightly more robust way to call `eager_tensor$numpy()`). 

In graph mode, `if` statements written in R automatically get translated to a `tf.cond()`. `tf.cond()` requires that both branches of the conditional are balanced (meaning, both branchs return the same output structure). `autograph()` tries to capture all locally modified variables, newly created variables, as well as the return value of the overall expression in the translated  `tf.cond()`, while satisfying the requirement for balanced branches.


```{r}
tf_sign <- tf_function(autograph(function(x) {
  if (x > 0)
    1
  else if (x < 0)
    -1
  else
    0
}))
```

Any variables that can't be balanced between the branches are exported as **undefined** objects (S3 class: `undef`). Undefined objects throw an informative error if you attempt to access them. The error message indicates which expression the undef originated from, and suggestions for how to prevent a symbol from being an `undef`. 
```{r, error = TRUE}
undef_example <- tf_function(autograph(function(x) {
  if (x > 0) {
    branch_local_tmp <- x + 1
    x <- branch_local_tmp + 1
    x
  }
  branch_local_tmp
}))
undef_example(tf$constant(1))
```


#### `while`

In eager mode, `while(eagor_tensor)` is translated to `while(as.logical(eager_tensor))`. (As a reminder, the `tensorflow` R package provides tensor methods for many S3 generics, including `as.logical()`).

Here is an example of an autographed `while` expression being evaluated eagerly. Remember, `autograph()` is not just for functions!

```{r}
total <- 1
x
autograph({
  while (x != 0) {
    message("Evaluating while body R expression")
    total %<>% multiply_by(x)
    x %<>% subtract(tf_sign(x))
  }
})
x
total
```


In graph mode, `while` expressions are translated to a `tf$while_loop()` call.
```{r}
tf_factorial <- tf_function(autograph(function(x) {
  total <- 1
  while (x != 0) {
    message("Evaluating while body R expression")
    total %<>% multiply_by(x)
    x %<>% subtract(tf_sign(x))
  }
  total
}))

tf_factorial(x)
tf_factorial(y)
```

[`tf.while_loop()`](https://www.tensorflow.org/api_docs/python/tf/while_loop)
has many options. In order to pass those through to the call, precede the
`while` expression with `ag_while_opts()`.


```{r}
tf_factorial_no_backprop <- tf_function(autograph(function(x) {
  total <- 1
  ag_while_opts(back_prop = FALSE)
  while (x != 0) {
    message("Evaluating while body R expression")
    total %<>% multiply_by(x)
    x %<>% subtract(tf_sign(x))
  }
  total
  }))
tf_factorial_no_backprop(y)
```


#### `for`
Autographed `for` loops build on top of while loops. `autograph` adds support for three new types of values passed to `for`: 
+  tfdatasets 
+  tensors
+  python iterators (eager mode only).

In eager mode, both datasets and tensors are coerced to iterators (via
```iterable$`__iter__`()```, through the ergonomic wrapper
`reticulate::as_iterator()`). The arguments are then iterated over until the
iterable is finished. Essentially, a call like
```{r, eval = FALSE}
for(elem in iterable) {...}
```
gets translated to
```{r, eval = FALSE}
iterator <- as_iterator(iterable)
while(!is.null(elem <- iter_next(iterator))) {...}
```

Note, that tensors are iterated over their first dimension.
```{r}
m <- tf$convert_to_tensor(matrix(1:12, nrow = 3, byrow = TRUE))
m
autograph({
  for (elem in m)
    print(elem)
})
```


In graph mode, `for` can accept a tensor or a dataset. 
```{r}
niave_reduce_sum <- tf_function(autograph(function(x, dtype = "int64") {
  running_total <- tf$zeros(list(), dtype)
  for (elem in x)
    running_total %<>% add(elem)
  
  running_total
}))
```

Works with a tensor: 
```{r}
niave_reduce_sum(tf$range(10L, dtype = "int64"))
```
and with a dataset:
```{r}
niave_reduce_sum(tf$data$Dataset$range(10L))
```

Since `for(var in tensor)` loops are powered by `tf$while_loop()`, 
you can pass additional options via `ag_while_opts()` just as you would to an
autographed `while()` expression.
```{r}
niave_reduce_sum_with_opts <- tf_function(autograph(function(x) {
  running_total <- tf$zeros(list(), x$dtype)
  
  ag_while_opts(parallel_iterations = 1)
  for (elem in x)
    running_total %<>% add(elem)
  
  running_total
}))

niave_reduce_sum_with_opts(tf$range(10))
```


# `break` / `next`

Loop control flow statements `break` and `next` are handled automatically by
`autograph()`, both in eager mode and graph mode. Use `break` and/or `next`
anywhere you would use it naturally in `while` and `for` loops.

# FizzBuzz!

Lets tie some concepts together to write
(fizzbuzz)[https://en.wikipedia.org/wiki/Fizz_buzz]! Before we do that, we'll
write a helper `tf_print()` that writes to a temporary file by default. This
will help us capture the output in this Rmarkdown vignette. (If we don't
redirect output to a file, then it would show up in the rendering console and
not in this vignette)
```{r}
TEMPFILE <- tempfile("tf-print-out", fileext = ".txt")

print_tempfile <-
  function(clear_after_read = TRUE, rewrap_lines = TRUE) {
    output <- readLines(TEMPFILE, warn = FALSE)
    if (clear_after_read) 
      unlink(TEMPFILE)
    if (rewrap_lines) 
      output <- strwrap(paste0(output, collapse = " "))
    writeLines(output)
  }

tf_print <- function(...)
  tf$print(..., output_stream = sprintf("file://%s", TEMPFILE))
```


```{r}
fizzbuzz <- autograph(function(n) {
  for (i in range_dataset(from = 1L, to = n)) {
    if (i %% 15L == 0L)
      tf_print("FizzBuzz")
    else if (i %% 3L == 0L)
      tf_print("Fizz")
    else if (i %% 5L == 0L)
     tf_print("Buzz")
    else
      tf_print(i)
  }
})
```


First, lets run it in eager mode.
```{r}
fizzbuzz(tf$constant(25L))
print_tempfile()
```
And now in graph mode.
```{r}
fizzbuzz <- tf_function(fizzbuzz)
fizzbuzz(tf$constant(25L))
print_tempfile()
```



## Visualize Function Graphs

As you are writing `tf.function()`s, it's helpful to visualize what the produced
graph from a particular autographed function looks like. Use
`tfautograph::view_function_graph()` to launchs a tensorboard and view the
function graph.

```{r, eval = FALSE}
view_function_graph(fizzbuzz, list(tf$constant(25L)))
```

## Control Dependencies
Check out the vignette on TF v1.

#### Growing Objects / TensorArrays

The package provides a `[<-` method for TensorArrays. That's the recomnded way
to grow objects on the graph.


#### How it works
`autograph()` works by evaluating expressions in an environment where primitives like `if` and `for` are masked by autographing versions of them. The complete list of which symbols are masked by `autograph()` is:   
```{r echo=FALSE}
names(tfautograph:::ag_mask_list)
```

### Other resources:

Check out the examples:
 Full MNIST training loop implemented in R using `autograph()`
