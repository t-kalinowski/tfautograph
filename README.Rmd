---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```
# tfautograph 
# :construction: **Under Construction** :construction:

<!-- badges: start -->
<!-- badges: end -->

This package implements autograph for R. It can be used to translate R control flow statements like `if` into tensorflow graphs.

Implemented so far:

 - [x] `if`
 - [x] `while` 
 - [x] `next` in `while` (python `continue`)
 - [x] `break` in `while`
 - [x] `for` with tensors
 - [x] `next/break` in `for` with tensors
 - [x] `for` with tf datasets
 - [x] `next/break` in `for` with tf datasets
 - [x] `stopifnot` (python `assert`)
 - [x] `switch` (autograph to `tf.switch_case`)
 - [ ] `print`, `stop` and `warning` (these fall into the same category as ops
 that need to be registered as control dependencies. Currently exploring
 (perhaps) more elegant solutions than the approach current implemented in
 `stopifnot`)
 
 
Additional remaining tasks:

 - [x] autograph inline expressions also, in addition to functions
 - [x] nice informative error messages warning about undefined symbols and unbalanced branches
 - [x] a way to pass through additional options to `tf.while_loop`
 - [ ] an escape hatch to prevent a specific statement from being autographed
 - [ ] a verbose/debug mode that logs what autograph is doing
 - [ ] R function documentation
 - [ ] vignette / README
 - [ ] submit to CRAN


Planned for CRAN release #2

 - [ ] early `return` in `while` and `for` 
 - [ ] autograph `if ... else if ... else if` chains into `tf.case` 
 - [ ] `recursive` support


# Quick Demo

Here is a full mnist training loop implemented in R using tfautograph. 
(adapted from [here](https://www.tensorflow.org/beta/guide/autograph))



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(magrittr)
library(purrr, warn.conflicts = FALSE)

library(tensorflow)
library(tfdatasets)
library(keras)

library(tfautograph)

# All of tfautograph works in tf 1.14 also, but this readme expects 2.0.
tf$version$VERSION
stopifnot(tf_version() >= "2")
```



### Download data


```{r}
prepare_mnist_features_and_labels <- function(x, y) {
  x = tf$cast(x, tf$float32) / 255
  y = tf$cast(y, tf$int64)
  list(x, y)
}

mnist_dataset <- function() {
  c(c(x, y), .) %<-% tf$keras$datasets$mnist$load_data()
  tensor_slices_dataset(list(x, y)) %>%
    dataset_map(prepare_mnist_features_and_labels) %>%
    dataset_take(20000) %>%
    dataset_shuffle(20000) %>%
    dataset_batch(100)
}

train_dataset <- mnist_dataset()
```


### Define the model
```{r}
model <- keras_model_sequential() %>%
  layer_reshape(target_shape = c(28 * 28),
                input_shape = shape(28, 28)) %>%
  layer_dense(100, activation = 'relu') %>%
  layer_dense(100, activation = 'relu') %>%
  layer_dense(10)
model$build()
optimizer <- tf$keras$optimizers$Adam() 
```


### Define the training loop
```{r, message=TRUE, warning=TRUE}
compute_loss <- tf$keras$losses$SparseCategoricalCrossentropy(from_logits = TRUE)
compute_accuracy <- tf$keras$metrics$SparseCategoricalAccuracy()

train_one_step <- function(model, optimizer, x, y) {
  with(tf$GradientTape() %as% tape, {
    logits <- model(x)
    loss <- compute_loss(y, logits)
  })

  grads <- tape$gradient(loss, model$trainable_variables)
  optimizer$apply_gradients(
    transpose(list(grads, model$trainable_variables)))

  compute_accuracy(y, logits)
  loss
}

# this is only so that Rmarkdown can capture output that would otherwise go to
# stdout
log_file <- sprintf("file://%s", tempfile("TF-print-log", fileext = ".out"))

train <- tf_function(autograph(function(model, optimizer) {
  train_ds <- mnist_dataset()
  step <- 0L
  loss <- 0
  ag_loop_vars("step", "loss") # to prevent `log_file` from being captured
  for (batch in train_ds) {
    c(x, y) %<-% batch
    step %<>% add(1L)
    loss <- train_one_step(model, optimizer, x, y)
    if (step %% 10L == 0L)
      tf$print('Step', step, ': loss', loss,
               '; accuracy', compute_accuracy$result(), 
               output_stream = log_file)
  }
  list(step, loss)
}))


c(step, loss) %<-% train(model, optimizer)
cat(readLines(log_file), sep = "\n")
cat('Final step ', as.array(step),
  ': loss ', as.array(loss),
  '; accuracy ', as.array(compute_accuracy$result()), "\n", sep = "")

```


## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("t-kalinowski/tfautograph")
```

